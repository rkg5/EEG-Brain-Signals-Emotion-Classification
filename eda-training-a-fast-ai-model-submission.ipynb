{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In order to get up and running quickly in this competition, let's look at:\n\n* [An overview of data](#section-one)\n* [Training a fast.ai model](#section-two)\n* [Making a first submission](#section-three)\n\n## Other resources you might find useful:\n\n* [💡 how to process DICOM images to PNGs](https://www.kaggle.com/code/radek1/how-to-process-dicom-images-to-pngs)\n* [🤖 [fast.ai starter pack] train + inference 🚀](https://www.kaggle.com/code/radek1/fast-ai-starter-pack-train-inference)\n\nLet's get started! 🚀","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n# Overview of data","metadata":{}},{"cell_type":"markdown","source":"In this competition our goal is to predict the presence or absence of cancer in mammography images.\n\n## How the data is organized\n\nThe images are organized in directories by patient id.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"ls ../input/rsna-breast-cancer-detection/train_images | head -1 -n 4","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:40.672636Z","iopub.execute_input":"2022-11-30T00:01:40.673326Z","iopub.status.idle":"2022-11-30T00:01:42.366939Z","shell.execute_reply.started":"2022-11-30T00:01:40.673200Z","shell.execute_reply":"2022-11-30T00:01:42.365892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each directory contains several images.","metadata":{}},{"cell_type":"code","source":"ls ../input/rsna-breast-cancer-detection/train_images/57175","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:42.370826Z","iopub.execute_input":"2022-11-30T00:01:42.371126Z","iopub.status.idle":"2022-11-30T00:01:43.340574Z","shell.execute_reply.started":"2022-11-30T00:01:42.371097Z","shell.execute_reply":"2022-11-30T00:01:43.339237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot as plt\n\nsample_sub = pd.read_csv('../input/rsna-breast-cancer-detection/sample_submission.csv')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-11-30T00:01:43.342387Z","iopub.execute_input":"2022-11-30T00:01:43.343248Z","iopub.status.idle":"2022-11-30T00:01:43.360828Z","shell.execute_reply.started":"2022-11-30T00:01:43.343152Z","shell.execute_reply":"2022-11-30T00:01:43.359733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For each patient, we are to predict the presence or absence of cancer in the left and right breast.\n\nHere is the submission format.","metadata":{}},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:43.365346Z","iopub.execute_input":"2022-11-30T00:01:43.365652Z","iopub.status.idle":"2022-11-30T00:01:43.388761Z","shell.execute_reply.started":"2022-11-30T00:01:43.365627Z","shell.execute_reply":"2022-11-30T00:01:43.387802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 11913 patients in the train set.","metadata":{}},{"cell_type":"code","source":"!ls -l ../input/rsna-breast-cancer-detection/train_images | wc -l # wc -l outputs one a count of one row too many when used like this! hence we need to subtract one to get the true count","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:43.390661Z","iopub.execute_input":"2022-11-30T00:01:43.391351Z","iopub.status.idle":"2022-11-30T00:01:44.434384Z","shell.execute_reply.started":"2022-11-30T00:01:43.391312Z","shell.execute_reply":"2022-11-30T00:01:44.433231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In test, we have access to just a single example!","metadata":{}},{"cell_type":"code","source":"ls ../input/rsna-breast-cancer-detection/test_images/10008","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:44.436197Z","iopub.execute_input":"2022-11-30T00:01:44.436944Z","iopub.status.idle":"2022-11-30T00:01:45.460285Z","shell.execute_reply.started":"2022-11-30T00:01:44.436901Z","shell.execute_reply":"2022-11-30T00:01:45.458965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nHowever, once we submit from our notebook, the full test set will get mounted.\n\nThe images we will work with are in the DICOM format. Let us take a closer look at it.","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:15:53.094510Z","iopub.execute_input":"2022-11-29T00:15:53.095003Z","iopub.status.idle":"2022-11-29T00:15:53.103826Z","shell.execute_reply.started":"2022-11-29T00:15:53.094963Z","shell.execute_reply":"2022-11-29T00:15:53.101863Z"}}},{"cell_type":"markdown","source":"## DICOM image format overview\n\nA DICOM file consists of a header and image data sets packed into a single file. The information within the header is organized as a constant and standardized series of tags. By extracting data from these tags one can access important information regarding the patient demographics, study parameters, etc.\n\nLet's look at a couple of images to gain a better intution on what types of images we are working here with.","metadata":{}},{"cell_type":"code","source":"import pydicom\nimport numpy as np\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom pathlib import Path\nimport glob","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-11-30T00:01:45.462464Z","iopub.execute_input":"2022-11-30T00:01:45.462827Z","iopub.status.idle":"2022-11-30T00:01:46.457659Z","shell.execute_reply.started":"2022-11-30T00:01:45.462797Z","shell.execute_reply":"2022-11-30T00:01:46.456701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, let's start with the metadata. Each image contains a rich metadata that might guide is in how we split the data for training (we might also want to provide some of this information directly to our model!)","metadata":{}},{"cell_type":"code","source":"example = '../input/rsna-breast-cancer-detection/train_images/10006/1459541791.dcm'\npydicom.dcmread(example)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:46.459036Z","iopub.execute_input":"2022-11-30T00:01:46.459487Z","iopub.status.idle":"2022-11-30T00:01:46.584391Z","shell.execute_reply.started":"2022-11-30T00:01:46.459442Z","shell.execute_reply":"2022-11-30T00:01:46.583413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now let us look at some images.","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:23:32.976227Z","iopub.execute_input":"2022-11-29T00:23:32.977415Z","iopub.status.idle":"2022-11-29T00:23:32.984473Z","shell.execute_reply.started":"2022-11-29T00:23:32.977365Z","shell.execute_reply":"2022-11-29T00:23:32.982948Z"}}},{"cell_type":"code","source":"# source: https://www.kaggle.com/code/allunia/rsna-csf-cervical-spine-fracture-eda/notebook\ndef rescale_img_to_hu(dcm_ds):\n    \"\"\"Rescales the image to Hounsfield unit.\"\"\"\n    data = dcm_ds.pixel_array\n    if dcm_ds.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    return data * dcm_ds.RescaleSlope + dcm_ds.RescaleIntercept","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-11-30T00:01:46.585837Z","iopub.execute_input":"2022-11-30T00:01:46.586170Z","iopub.status.idle":"2022-11-30T00:01:46.591978Z","shell.execute_reply.started":"2022-11-30T00:01:46.586136Z","shell.execute_reply":"2022-11-30T00:01:46.590938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images_for_patient(patient_id):\n    patient_dir = os.path.join('../input/rsna-breast-cancer-detection/train_images', str(patient_id))\n    num_images = len(glob.glob(f\"{patient_dir}/*\"))\n    print(f\"Number of images for patient: {num_images}\")\n    fig, axs = plt.subplots(2, 2, figsize=(24,15))\n    axs = axs.flatten()\n    for i, img_path in enumerate(list(Path(patient_dir).iterdir())):\n        ds = pydicom.dcmread(img_path)\n        axs[i].imshow(rescale_img_to_hu(ds), cmap=\"bone\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-11-30T00:01:46.596665Z","iopub.execute_input":"2022-11-30T00:01:46.597582Z","iopub.status.idle":"2022-11-30T00:01:46.604782Z","shell.execute_reply.started":"2022-11-30T00:01:46.597546Z","shell.execute_reply":"2022-11-30T00:01:46.603798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_images_for_patient(10006)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:01:46.606312Z","iopub.execute_input":"2022-11-30T00:01:46.606786Z","iopub.status.idle":"2022-11-30T00:02:04.973972Z","shell.execute_reply.started":"2022-11-30T00:01:46.606752Z","shell.execute_reply":"2022-11-30T00:02:04.972041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see from the plots, the images are of considerable size.\n\nWe see that the breast occupies only a small portion of the image.\n\nAs such (especially given the limited compute budget!) it will most likely be a very good idea to find ways of cropping out the portions of the image htat do not contain any information! The divider line can serve an important role here.","metadata":{}},{"cell_type":"markdown","source":"## The competition metric\n\nIt is always a good idea to understand exactly the type of predictions our model will be required to deliver.\n\nThe metric that the organizers opted for here is the probabilistic F1 score:\n\n$pF_1 = 2\\frac{pPrecision \\cdot pRecall}{pPrecision+pRecall}$\n\nwith:\n\n$pPrecision = \\frac{pTP}{pTP+pFP}$\n\n$pRecall = \\frac{pTP}{pTP+pFN}$\n\nYou can find a Python implementation of the metric [here](https://www.kaggle.com/code/sohier/probabilistic-f-score)\n\nOur model should output the likelihood of cancer in the corresponding image.\n\nSo what are the labels we will train on?","metadata":{}},{"cell_type":"code","source":"train_csv = pd.read_csv('../input/rsna-breast-cancer-detection/train.csv')\ntrain_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:02:04.975015Z","iopub.execute_input":"2022-11-30T00:02:04.975365Z","iopub.status.idle":"2022-11-30T00:02:05.075715Z","shell.execute_reply.started":"2022-11-30T00:02:04.975318Z","shell.execute_reply":"2022-11-30T00:02:05.074684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The targets are stored in the `train.csv` file along with some additional metadata.\n\nThey are stored in the `cancer` column. Additionally, the file provides mapping of images to `laterality` (whether an image is of the left or right breast -- this can be very useful in training).\n\nAnd where can we find information on `laterality` (and other metadata) in test?\n\nIt is contained in the `test.csv` file.","metadata":{}},{"cell_type":"code","source":"test_csv = pd.read_csv('../input/rsna-breast-cancer-detection/test.csv')\ntest_csv","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:02:05.077656Z","iopub.execute_input":"2022-11-30T00:02:05.078308Z","iopub.status.idle":"2022-11-30T00:02:05.096879Z","shell.execute_reply.started":"2022-11-30T00:02:05.078266Z","shell.execute_reply":"2022-11-30T00:02:05.095855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the test file doesn't contain the `cancer` column.\n\nSo how many images do we have to train on?","metadata":{"execution":{"iopub.status.busy":"2022-11-29T00:49:29.188171Z","iopub.execute_input":"2022-11-29T00:49:29.188600Z","iopub.status.idle":"2022-11-29T00:49:29.218817Z","shell.execute_reply.started":"2022-11-29T00:49:29.188566Z","shell.execute_reply":"2022-11-29T00:49:29.217571Z"}}},{"cell_type":"code","source":"train_csv.shape[0], train_csv.patient_id.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:02:05.098612Z","iopub.execute_input":"2022-11-30T00:02:05.098964Z","iopub.status.idle":"2022-11-30T00:02:05.111964Z","shell.execute_reply.started":"2022-11-30T00:02:05.098929Z","shell.execute_reply":"2022-11-30T00:02:05.110659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a total of 54706 images in train across 11913 patients.","metadata":{}},{"cell_type":"markdown","source":"## Distribution of labels","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\nplt.subplot(1,2,1)\nax1 = sns.countplot(data=train_csv, x='cancer')\nfor container in ax1.containers:\n    ax1.bar_label(container)\nplt.title('Distribution of targets');","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:02:05.113670Z","iopub.execute_input":"2022-11-30T00:02:05.114040Z","iopub.status.idle":"2022-11-30T00:02:05.320736Z","shell.execute_reply.started":"2022-11-30T00:02:05.114004Z","shell.execute_reply":"2022-11-30T00:02:05.319681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The classes are highly unbalanced! Most likely, we will need to address this in training (possibly via upsampling of the `cancer` class, downsampling of the `cancer absent`, class weights, etc).","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n# Training a fast.ai model","metadata":{}},{"cell_type":"markdown","source":"Let's now put all the pieces in place that we will need to trian a fast.ai model\n\nTo facilitate quick experimentation, I have processed [train images to PNGs](https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/369282) and shared them here: [RSNA Mammography -- images as PNGs (256px & 512px)](https://www.kaggle.com/datasets/radek1/rsna-mammography-images-as-pngs).\n\nHere is everything that we need in order to get up and runnig quickly with the fast.ai library.","metadata":{}},{"cell_type":"markdown","source":"## Creating dataloaders","metadata":{}},{"cell_type":"code","source":"from fastai.data.all import *\nfrom fastai.vision.all import *\n\npath = '../input/rsna-mammography-images-as-pngs/images_as_pngs/train_images_processed'\n\ntrain_csv = pd.read_csv('../input/rsna-breast-cancer-detection/train.csv')\nfn2label = {fn: cancer_or_not for fn, cancer_or_not in zip(train_csv['image_id'].astype('str'), train_csv['cancer'])}\n\ndef label_func(path):\n    return fn2label[path.stem]\n\ndblock = DataBlock(\n    blocks    = (ImageBlock, CategoryBlock),\n    get_items = get_image_files,\n    get_y = label_func,\n    splitter  = RandomSplitter()\n)\ndsets = dblock.datasets(path)\ndls = dblock.dataloaders(path)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:02:05.322633Z","iopub.execute_input":"2022-11-30T00:02:05.322988Z","iopub.status.idle":"2022-11-30T00:03:02.202802Z","shell.execute_reply.started":"2022-11-30T00:02:05.322951Z","shell.execute_reply":"2022-11-30T00:03:02.201802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And this is what a batch of our data will look like!","metadata":{}},{"cell_type":"code","source":"dls.show_batch()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:03:02.204088Z","iopub.execute_input":"2022-11-30T00:03:02.204451Z","iopub.status.idle":"2022-11-30T00:03:03.247298Z","shell.execute_reply.started":"2022-11-30T00:03:02.204414Z","shell.execute_reply":"2022-11-30T00:03:03.246288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating the learner and training for a single epoch","metadata":{}},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate, pretrained=False)\nlearn.fit_one_cycle(1, 1e-2)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:03:03.248834Z","iopub.execute_input":"2022-11-30T00:03:03.249440Z","iopub.status.idle":"2022-11-30T00:06:23.054684Z","shell.execute_reply.started":"2022-11-30T00:03:03.249395Z","shell.execute_reply":"2022-11-30T00:06:23.053659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is a lot of functionality in the fast.ai toolkit that can be particularly useful in this competition:\n\n* training with one cycle (to make the best use of resources on Kaggle and to train better models)\n* the [medical imaging module](https://docs.fast.ai/medical.imaging.html) that we can use for reading DICOM files directly\n* image augmentation on the GPU (augmenting images is a compute-intensive process, on Kaggle we only have 2 CPU cores on GPU VMs so offloading augmenting our data to the super computer that a GPU is might lead to faster training)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n# First submission\n\nLet's take a look at how to create a first submission to understand what format of predictions is expected (and how to output them).\n\nIn the notebook, we don't have access to the actual test set, that is until we submit! Once we finish editing our notebook and submit, the full test set will get mounted to our notebook.\n\nIt will follow the structure of the stub test set we have mounted currently, but will contain more than just the single directory.\n\nHere is what is currently mounted as the test set:","metadata":{}},{"cell_type":"code","source":"ls ../input/rsna-breast-cancer-detection/test_images","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:06:23.056626Z","iopub.execute_input":"2022-11-30T00:06:23.056999Z","iopub.status.idle":"2022-11-30T00:06:24.058544Z","shell.execute_reply.started":"2022-11-30T00:06:23.056958Z","shell.execute_reply":"2022-11-30T00:06:24.057364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's put all of the machinery in place we will need for outputting predictions (and test that we got it right by outputting a prediction consisting of random floats between 0 and 1).\n\nIf our submission gets scored, we will know we got this right.","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame(data={'prediction_id': test_csv['prediction_id'], 'cancer': np.random.rand(test_csv.shape[0])}).drop_duplicates(subset='prediction_id')\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:06:24.060406Z","iopub.execute_input":"2022-11-30T00:06:24.062045Z","iopub.status.idle":"2022-11-30T00:06:24.079506Z","shell.execute_reply.started":"2022-11-30T00:06:24.061997Z","shell.execute_reply":"2022-11-30T00:06:24.078317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T00:06:24.081581Z","iopub.execute_input":"2022-11-30T00:06:24.082555Z","iopub.status.idle":"2022-11-30T00:06:24.091281Z","shell.execute_reply.started":"2022-11-30T00:06:24.082514Z","shell.execute_reply":"2022-11-30T00:06:24.090244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And that's it! Thank you very much for reading! 🙂\n\n**If you enjoyed the notebook, please upvote! 🙏 Thank you, appreciate your support!**\n\nHappy Kaggling 🥳\n","metadata":{}}]}